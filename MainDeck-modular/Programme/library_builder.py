from pathlib import Path
import pandas as pd
import json, re, sys
import math

# -------------------------------------------------- Konfiguration
EXCEL_FILE  = Path("../Stud-Monitoring-neu.xlsm")   # Pfad zur Excel‚ÄëDatei
QUERY_NAME  = "Abfrage"                             # Blatt / Tabelle der sortierten Query
HEADER_ROW  = 0                                     # Header befindet sich in Zeile‚ÄØ1

LIB_DIR  = Path("Library")
LIB_DIR.mkdir(exist_ok=True)

LIB_TEX  = LIB_DIR / "Library.tex"
LIB_JSON = LIB_DIR / "Library.json"

ADDITIONAL = ["Layer", "Comp", "RelInt", "RelId", "Cont", "Cint", "CID"]

ENV = {  # CTyp ‚Üí LaTeX‚ÄëEnvironment
    "DEF": "DEF",  "EXA": "EXA",  "PROP": "PROP",  "THEO": "THEO",
    "KORO": "KORO","LEM": "LEM",  "REM": "REM",   "STUD": "STUD",
    "PRF": "PRF",  "CONC": "CONC",
}

HEADER_MARK = "%-- AUTO-UNITS-START -------------------------------------------\n"
TAIL_MARK   = r"\pagebreak"        # Ende des Auto‚ÄëBereichs (ggf. anpassen)

# -------------------------------------------------- Excel einlesen
print("üì•  Lese Excel¬†‚Ä¶")
try:
    df = pd.read_excel(EXCEL_FILE, sheet_name=QUERY_NAME, header=HEADER_ROW)
except ValueError as e:
    sys.exit(f"‚ùå  {e}")

# Spalten‚ÄëAlias‚ÄëMapping (robust gegen Gro√ü/Klein)
aliases = {"unitid": "UnitID", "subject": "Subject", "topic": "Topic",
           "ctyp": "CTyp", "content": "Content"}
df.columns = [c.strip() for c in df.columns]
norm = {c.lower(): c for c in df.columns}
missing = [aliases[k] for k in aliases if k not in norm]
if missing:
    sys.exit(f"‚ùå  Spalten fehlen: {missing}\nVorhanden: {list(df.columns)}")

base_cols = [norm[k] for k in aliases]
opt_cols  = [c for c in ADDITIONAL if c in df.columns]
df        = df[base_cols + opt_cols].dropna(subset=[norm["unitid"],
                                                   norm["ctyp"],
                                                   norm["content"]])

records = df.to_dict("records")

# -------------------------------------------------- Library.tex laden oder erstellen
if LIB_TEX.exists():
    tex_src = LIB_TEX.read_text(encoding="utf-8")
else:
    tex_src = ""

# Header bei Erst¬≠erstellung einf√ºgen
if HEADER_MARK not in tex_src:
    tex_src = r"""\documentclass[10pt, letterpaper]{article}
% ‚Ä¶ dein fixer Header ‚Ä¶
""" + HEADER_MARK + TAIL_MARK + "\n\\end{document}\n"

# -------------------------------------------------- Auto‚ÄëBereich herausl√∂sen
try:
    head, tail = tex_src.split(HEADER_MARK, 1)
    auto, rest = tail.split(TAIL_MARK, 1)
except ValueError:
    sys.exit("‚ùå  HEADER_MARK oder TAIL_MARK nicht gefunden ‚Äì Library.tex pr√ºfen")

block_pat = re.compile(r"\\begin\{\w+\}\{([^}]*)\}.*?\\end\{\w+\}\s*", re.S)
block_map = {m.group(1): m.group(0) for m in block_pat.finditer(auto)}

# -------------------------------------------------- Fehlende Units erzeugen
added = 0
for rec in records:
    uid = rec["UnitID"]
    if uid in block_map:         # bereits vorhanden
        continue
    env   = ENV.get(rec["CTyp"], "REM")
    title = str(rec["Content"]).strip()
    block_map[uid] = (f"\\begin{{{env}}}{{{uid}}}{{{title}}}\n"
                      f"% TODO: Inhalt erg√§nzen (Tex)\n"
                      f"\\end{{{env}}}\n\n")
    added += 1

# -------------------------------------------------- Reihenfolge exakt wie in Abfrage
excel_order = df[norm["unitid"]].tolist()         # bereits sortiert (Subject‚ÜíTopic‚ÜíNr.)
for uid in block_map:                             # Alt‚ÄëIDs (falls vorhanden) anh√§ngen
    if uid not in excel_order:
        excel_order.append(uid)

sorted_blocks = [block_map[uid] for uid in excel_order]
new_auto      = "".join(sorted_blocks)

# -------------------------------------------------- Library.tex zur√ºckschreiben
tex_src = head + HEADER_MARK + new_auto + TAIL_MARK + rest
LIB_TEX.write_text(tex_src, encoding="utf-8")

if added:
    print(f"‚úÖ  {added}‚ÄØneue Units einsortiert.")
else:
    print("‚ÑπÔ∏è  Keine fehlenden Units ‚Äì Library.tex unver√§ndert.")

# --------- NaN ‚Üí None -------------------------------------------------
for rec in records:
    for k, v in rec.items():
        if isinstance(v, float) and math.isnan(v):
            rec[k] = None

# -------------------------------------------------- JSON komplett neu schreiben
with open(LIB_JSON, "w", encoding="utf-8") as fh:
    json.dump(records, fh, indent=2, ensure_ascii=False, allow_nan=False)

print(f"‚úÖ  Library.json vollst√§ndig √ºberschrieben mit {len(records)} Eintr√§gen.")

